{"cells":[{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["def _get_spark():\n  spark = SparkSession.builder.appName(\"project_customer_360_campaign_test\").getOrCreate()\n  spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n  spark.conf.set(\"spark.sql.parquet.binaryAsString\", \"true\")\n  spark.conf.set(\"spark.sql.shuffle.partitions\", 200)\n  spark.conf.set(\"spark.sql.files.maxPartitionBytes\", 1024*1024*256)\n  return spark\nspark = _get_spark()\nspark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# Below Command are executed only once to mount the blob as a mount volume on Databricks\n# Mount Points:\n# Blob Storage customer360-blob-data is available at mount point /mnt/customer360-blob-data\n# Blob Storage customer360-blob-output is available at mount point /mnt/customer360-blob-output\nimport pandas as pd\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\n\nfrom pyspark.sql.functions import *\n\nimport sys\nsys.version_info\nspark.conf.set(\"spark.sql.parquet.binaryAsString\",\"true\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.sources.partitionOverwriteMode\", \"DYNAMIC\")\nimport datetime\n\ndt = datetime.datetime(2019, 8, 1)\nend = datetime.datetime(2020, 2, 14)\nstep = datetime.timedelta(days=1)\n\nresult = []\ndf = spark.read.parquet(\"dbfs:/mnt/customer360-blob-output/C360/PROFILE/l1_features/l1_customer_profile_union_daily_feature/event_partition_date=2020-02-14/\")\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["while dt < end:\n  partition_date = dt.strftime('%Y-%m-%d')\n  result.append(partition_date)\n  dt += step\n  # only save whatever active before or at current date\n  filtered_df = df.filter(col(\"register_date\") <= to_date(lit(partition_date)))\\\n  .withColumn(\"event_partition_date\", F.to_date(F.lit(partition_date)))\\\n  .withColumn(\"start_of_week\", F.to_date(F.date_trunc('week', F.col(\"event_partition_date\"))))\\\n  .withColumn(\"start_of_month\", F.to_date(F.date_trunc('month', F.col(\"event_partition_date\"))))\n                          \n\n  (filtered_df.write\n   .partitionBy(\"event_partition_date\")\n   .mode(\"overwrite\")\n   .parquet(\"dbfs:/mnt/customer360-blob-output/C360/PROFILE/l1_features/l1_customer_profile_union_daily_feature/\"))\n\n  print(partition_date)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":6}],"metadata":{"name":"backfill_L1_customer_profile","notebookId":3213892385568037},"nbformat":4,"nbformat_minor":0}
