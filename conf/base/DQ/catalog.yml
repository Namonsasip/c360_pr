_spark_parquet: &spark_parquet
  type: kedro.contrib.io.pyspark.SparkDataSet
  file_format: "parquet"

dq_sampled_subscription_identifier: &dq_sampled_subscription_identifier
  <<: *spark_parquet
  filepath: dq_path/DQ/nba_features/dq_sampled_subscription_identifier/
  save_args:
    partitionBy: ["created_date"]
    mode: "append"

dq_accuracy_and_completeness:
  <<: *spark_parquet
  filepath: dq_path/DQ/nba_features/dq_accuracy_and_completeness/
  save_args:
    mode: "append"
    partitionBy: ["dataset_name", "corresponding_date"]

dq_availability:
  <<: *spark_parquet
  filepath: dq_path/DQ/nba_features/dq_availability/
  save_args:
    mode: "overwrite"
    partitionBy: ["dataset_name", "run_date"]

dq_consistency:
  <<: *spark_parquet
  filepath: dq_path/DQ/nba_features/dq_consistency
  save_args:
    mode: "append"
    partitionBy: ["dataset_name", "run_date"]

dq_timeliness:
  <<: *spark_parquet
  filepath: dq_path/DQ/nba_features/dq_timeliness/
  save_args:
    mode: "overwrite"
    partitionBy: ["dataset_name", "run_date"]
