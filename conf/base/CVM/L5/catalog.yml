_spark_parquet: &spark_parquet
  type: kedro.contrib.io.pyspark.SparkDataSet
  file_format: "parquet"
  save_args:
    mode: "overwrite"

# feature important columns
important_columns:
  type: kedro.contrib.io.yaml_local.YAMLLocalDataSet
  filepath: /dbfs/mnt/customer360-cvm/important_columns

null_columns:
  type: kedro.contrib.io.yaml_local.YAMLLocalDataSet
  filepath: /dbfs/mnt/customer360-cvm/null_columns

# diagnostic metric, plots and tables
models_diags:
  type: kedro.io.PickleLocalDataSet
  filepath: /dbfs/mnt/customer360-cvm/models_diags

sub_id_mapping:
  <<: *spark_parquet
  filepath: dbfs:/mnt/customer360-blob-data/C360/CVM/l5_cvm_sub_id_mapping/

preprocessing_pipeline:
  type: datasets.ml_pipeline.MLPipeline
  filepath: /dbfs/mnt/customer360-cvm/preprocessing_pipeline

random_forest:
  type: kedro.io.PickleLocalDataSet
  filepath: /dbfs/mnt/customer360-cvm/random_forest

treatments_chosen:
  type: kedro.io.csv_local.CSVLocalDataSet
  filepath: /dbfs/mnt/customer360-cvm/treatments_chosen.csv

treatments_chosen_history_input:
  <<: *spark_parquet
  filepath: dbfs:/mnt/customer360-blob-data/C360/CVM/l5_cvm_treatments_chosen_history/

# The same as above - used when the dataset is both an input and output of a node
treatments_chosen_history_output:
  <<: *spark_parquet
  filepath: dbfs:/mnt/customer360-blob-data/C360/CVM/l5_cvm_treatments_chosen_history/

# technical dataset - used to properly topologically sort the pipeline
treatments_deployed:
  type: kedro.io.PickleLocalDataSet
  filepath: /dbfs/mnt/customer360-cvm/treatments_deployed
