#spark_conf:
#  spark.driver.memory: 256g
#  spark.executor.cores: 4
#  spark.executor.memory: 48g
#  spark.dynamicAllocation.enabled: true
#  spark.dynamicAllocation.initialExecutors: 10
#  spark.dynamicAllocation.maxExecutors: 150
#  spark.sql.sources.partitionOverwriteMode: dynamic
#  spark.sql.parquet.binaryAsString: true
#  spark.hadoop.fs.permissions.umask-mode: "002"
#  spark.executor.memoryOverhead: 16g
#  spark.debug.maxToStringFields: 100
#  spark.port.maxRetries: 100
#  spark.sql.shuffle.partitions: 1500
#  spark.sql.files.maxPartitionBytes: 1073741824
#  #  spark.executor.extraJavaOptions: "-Xss512m"




# Revenue L4 Config
spark_conf:
  spark.yarn.queue: pr_c360
  spark.submit.deployMode: client
  spark.driver.memory: 256g
  spark.executor.cores: 16
  spark.executor.memory: 256g
  spark.dynamicAllocation.enabled: false
  #spark.dynamicAllocation.initialExecutors: 50
  #spark.dynamicAllocation.maxExecutors: 100
  spark.executor.instances: 150
  spark.sql.sources.partitionOverwriteMode: dynamic
  spark.sql.parquet.binaryAsString: true
  spark.hadoop.fs.permissions.umask-mode: "002"
  spark.executor.memoryOverhead: 64g
  spark.debug.maxToStringFields: 100
  spark.port.maxRetries: 100
  spark.sql.shuffle.partitions: 1000
  spark.sql.files.maxPartitionBytes: 1073741824
  spark.sql.autoBroadcastJoinThreshold: -1
  spark.ui.showConsoleProgress: false
  #spark.executor.extraJavaOptions: "-Xss512m"
  #spark.executor.extraJavaOptions: "-Xss512m"

